[package]
name = "rusty-cli"
version = "0.1.0"
edition = "2024"
description = "A Rust-based CLI to chat with LLMs from multiple providers (OpenAI, Ollama, etc.)."
authors = ["Your Name <you@example.com>"]
license = "MIT OR Apache-2.0"

[dependencies]
clap = { version = "4", features = ["derive"] }
tokio = { version = "1", features = ["rt-multi-thread", "macros", "process", "io-util"] }
reqwest = { version = "0.12", features = ["json", "stream", "gzip", "brotli", "deflate", "rustls-tls"] }
serde = { version = "1", features = ["derive"] }
serde_json = "1"
thiserror = "1"
dotenvy = "0.15"
futures-util = "0.3"
colored = "2"
anyhow = "1"
async-trait = "0.1"
toml = "0.8"
dirs = "5"
time = { version = "0.3", features = ["macros"] }
blake3 = "1"
tokio-stream = { version = "0.1", features = ["io-util"] }
html-escape = "0.2"
tinytemplate = "1.2"
strip-ansi-escapes = "0.2"

[profile.release]
codegen-units = 1
lto = true
opt-level = "z"
strip = true
tokio = { version = "1", features = ["rt-multi-thread", "macros", "process", "io-util"] }
